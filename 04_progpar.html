<!doctype html>

<html lang=es>
	<head>
		<title>Programción paralela</title>
		<meta charset=utf-8>
		<meta name=author content="Antonio Cepero">
		<meta name=created content="2021-06-14">
		<meta name=modified content="2021-08-25">
		<link rel=stylesheet href="estilo.css">

<!--
	Soporte para la introducción de MathML
	Sería mejor eliminarlo si es Firefox, con soporte nativo,
	pero lo dejo para más adelante
--!>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
	</head>
	<body>
		<article>
			<header>
				<h1>Programación paralela</h1>
			</header>
			<nav class=toc>
				<ol>
					<li><a href=#recursividad>Recursividad</a></li>
					<li><a href=#creatarea>Creación de tareas</a></li>
					<li><a href=#fjframework><em>Fork-Join Framework</em></a></li>
					<li><a href=#amdhal>Ley de Amdhal</a></li>
					<li><a href=#streams>Streams en Java</a></li>

				</ol> 
			</nav>
			<section id=Recursividad>
				<header>
					<h1 id=recursividad>Recursividad</h1>
				</header>
<p>Vamos a comenzar hablando de lo que es la recursividad. La recursividad,
que merecería un tema dedicado a la misma por sí sola, es una técnica muy
poderosa que podemos utilizar en lugar de la iteración -y Java nos
proporciona un framework que nos permite resolver problemas recursivos de
forma paralela eficientemente-.
<p>En general, la recursividad nos proporciona un modo distinto de ver las
repeticiones y, aunque las soluciones recursivas suelen ser menos eficientes
que las iterativas, para el mismo problema, en muchos casos la solución
recursiva es elegante y simple, mientras que resulta muy complejo
resolverlo iterativamente.
<p>Pero vamos a ver en qué consiste ¿Recordáis qué es una matrioska? Esas
muñecas rusas que se guardan unas dentro de otras, de forma que en el
interior de cada una de ellas hay otra más pequeña. Un algoritmo recursivo
es como un conjunto de matrioskas: se reproduce a sí mismo con ejemplares
más y más pequeños hasta que se encuentra la solución (no hay más muñecas).
<p>Imaginad la exponenciación:
<p><span class=code>X<sup>n</sup> = X * X * X * ... * X</span>
<p>que también podemos escribir como:
<p><span class=code>X<sup>n</sup> = X * X<sup>n-1</sup></span>
<p>Esto es una definición recursiva: la definición se da en términos de una versión más pequeña de sí misma.
<p>Veamos algunas definiciones:
<dl>
	<dt>Caso base</dt>
	<dd>Caso para el que la solución puede establecerse en forma no
	recursiva</dd>
	<dt>Caso general</dt>
	<dd>Caso para el que la solución se expresa en términos de una
	versión más pequeña de sí mismo</dd>
	<dt>Algoritmo recursivo</dt>
	<dd>Solución que se expresa en términos de (a) instancias más
	pequeñas de sí mismo y (b) un caso base</dd>
</dl>
<p>¿Cuándo se detiene el proceso? Cuando hemos alcanzado un caso para el
que conocemos la respuesta sin tener que volver a aplicar la recursividad.
Como hemos indicado, decimos que el caso para el que la solución se expresa
en términos de forma no recursiva es el caso base.
<p>Supongamos el caso de la exponenciación:
<pre class=code>
	double exp ( double x, int n ) {
		return x * exp(x, n-1); //¿Fin?
	}
</pre>
<p>sabemos que, cuando <em>n</em> es uno, X<sup>1</sup> es X. Ese es nuestro
caso base, aquél del que conocemos la respuesta de forma explícita:
<pre class=code>
	double exp ( double x, int n ) {
		if ( n == 1 )
			return x; // Fin
		return x * exp(x, n-1);
	}	
</pre>
<p>También podríamos haber utilizado como caso base aquél en que <em>n</em> es
cero ya que, como sabemos, cualquier número elevado a cero es uno:
<br><span class=code>X<sup>0</sup> = 1</span>
<br>todo dependerá del dominio que defináis para <em>n</em>.
<p><b>Ejercicio: Factorial de un número (N!)</b>
<br>Resolver el problema del factorial de un número N. El factorial de un
número es dicho número multiplicado por el número menos uno, por el número
menos dos, etc. El factorial de cero es uno.
<br><span class=code>N! = N * (N-1) * (N-2) * (N-3) …</span>
<br><span class=code>0! = 1</span>
<p>Los métodos de cálculo de la exponenciación y el factorial son muy
simples. En realidad, solo son útiles para entender la recursividad y,
en la práctica, usaríamos una solución iterativa, que es más sencilla
y más eficiente.
<p>Os animo a que hagáis la versión iterativa. La diferencia principal
es que la versión iterativa necesita de un par de variables (para el
acumulador y el contador), que la versión recursiva no. El bucle tampoco
es necesario en la versión recursiva, aunque requiere una condición
(o bifurcación).
<p>
<b>Ejercicio: Convertir un número decimal (base 10) a binario (base 2)</b>
<ol>
	<li>Dividir el decimal por 2
	<li>El resto obtenido será el bit de menos peso (el de más a
		la derecha)
	<li>Utilizar ahora el cociente como dividendo
	<li>Repetir, colocando cada resto a la izquierda del anterior
	<li>Hasta que el cociente sea cero
</ol>
<p>Al hacer el algoritmo, podríamos sustituir lo que dice el punto dos por:
"Si el número es impar, el bit de menos peso será 1; si es par, será 0".
Además, los puntos 1 y 2 pueden ser intercambiandos.
<p>Nota: Podéis intentar hacerlo en secuencial antes de implementar la solución recursiva
<h2>Conclusión</h2>
<p>En definitiva, <b>¿cuándo podemos usar la recursividad y cómo debemos
	hacerlo?</b>
<ol>
	<li>Asegurarse de que existe un caso base
	<li>No utilizar una estructura repetitiva (WHILE). La estructura
		básica es una selección (IF), debiendo existir, al menos,
		dos casos: el recursivo	y el base.
		Puede suceder que el caso base no haga nada,
		pero debe existir la estructura de selección.
	<li>Procurar utilizar solo variables locales al método recursivo.
		Algunos objetos pueden ser globales si se opera sobre datos
		disjuntos como, por ejemplo, los elementos de un vector.
	<li>Los parámetros formales (tamaño del problema) deben ser siempre
		por valor; no modificar objetos pasados como parámetros.
</ol>
<h2>Ejercicios</h2>
<ol>
	<li>Escribir una función recursiva que calcule el
<a target=_blank href=https://es.wikipedia.org/wiki/Sucesi%C3%B3n_de_Fibonacci#Definici%C3%B3n_recurrente>número de Fibonacci</a>
<li>Escribir un comprobador (recursivo) de
<a target=_blank href=https://dle.rae.es/pal%C3%ADndromo>palíndromo</a>
<li>Implementad el problema de las
	<a target=_blank href=https://es.wikipedia.org/wiki/Torres_de_Han%C3%B3i>torres de Hanoi</a>
(Vídeo de
	<a target=_blank href=https://www.youtube.com/watch?v=LM68IQvIo_E>Derivando</a>)
<li>Implementad el algoritmo de ordenación rápida
(<a target=_blank href=https://es.wikipedia.org/wiki/Quicksort>Quicksort</a>)
<li>Realizad el
	<a target=_blank href=https://es.wikipedia.org/wiki/Problema_de_las_ocho_reinas>problema de las ocho reinas</a>: colocad en un tablero de ajedrez 8 reinas sin que se maten entre ellas.

</ol>

			</section>
			<section id=CreaTarea>
				<header>
					<h1 id=creatarea>Creación de tareas</h1>
				</header>
<p>Supongamos que tenemos una secuencia de tareas o instrucciones S1, S2, S3…
Nuestro objetivo consiste en determinar <em>cuáles de ellas pueden ejecutarse
en paralelo y cómo podemos coordinar ese paralelismo</em>.
<p>Vamos a imaginar que tenemos un vector y que queremos sumarlos. El algoritmo
es simple: utilizamos un acumulador -<em>suma</em>, inicializado a cero- al
que vamos sumando cada uno de los elementos del vector, por ejemplo, con un
bucle. El acumulador contendrá la suma de los elementos del vector.
¿Qué sucedería si dividimos el vector en dos partes, izquierda y derecha?
Podríamos obtener la suma de los elementos de la parte izquierda como
<em>suma_izq</em> y la suma de los elementos de la parte derecha como
<em>suma_dch</em>.
La <em>suma</em> de los elementos del vector, ahora, será la misma que si
sumamos <em>suma_izq</em> y <em>suma_dch</em>.
<br><span class=code>suma_izq = suma de la parte izquierda</span>
<br><span class=code>suma_dch = suma de la parte derecha</span>
<br><span class=code>suma = suma_izq + suma_dch</span>
<br>Esto se puede hacer secuencialmente pero, ¿cómo podemos hacerlo en paralelo?
<p>Vamos a usar una notación en la que a una instrucción vamos a precederla
de la palabra <span class=palabra>ASYNC</span> que, a su vez, será una
instrucción. Esta instrucción <span class=palabra>ASYNC</span> indica que la
instrucción que la sigue debe ejecutarse de forma asíncrona. La idea de la
asincronía hace referencia a que no tiene correspondencia en el tiempo; en
nuestro concepto de paralelismo, la instrucción
<span class=palabra>ASYNC</span>
implica que puede hacerse antes que lo que la sigue, después de lo que la
sigue o, como nos interesa a nosotros, a la vez (en paralelo) que lo que
viene a continuación.
<br><span class=code><span class=palabra>ASYNC</span> suma_izq = suma de la parte izquierda</span>
<br><span class=code>suma_dch = suma de la parte derecha</span>
<br><span class=code>suma = suma_izq + suma_dch</span>
<p>Una vez que tenemos la suma de los elementos de la parte derecha, queremos
obtener la suma total (que es la instrucción que debe ejecutarse a
continuación); para ello necesitamos tener también la suma de los
elementos de la parte izquierda. Debemos fijarnos en que <em>suma_izq</em>,
al ejecutarse en forma asíncrona con lo que viene a continuación, puede
finalizar más tarde que <em>suma_dch</em> y el sistema intentaría realizar
la suma de ambas partes aun cuando la izquierda pudiera no estar
disponible. Lo que deseamos es que puedan ejecutarse
de forma asíncrona todas las tareas que no necesitan hacerlo secuencialmente
y que, de algún modo, cuando tengamos que continuar, esperemos a que todas
ellas se hayan completado. Vamos a introducir una notación
<span class=palabra>FINISH</span> que va a hacer exactamente lo que buscamos.
Si hemos asociado un <span class=palabra>ASYNC</span> a <em>suma_izq</em>
y encerramos ahora <em>suma_izq</em> y <em>suma_dch</em> entre
<span class=palabra>FINISH</span>, vamos a estar seguros de que tanto
<em>suma_izq</em> como <em>suma_dch</em> se habrán completado antes de
proceder a calcular <em>suma</em>, combinando ambos valores.
<pre class=code>
<span class=palabra>FINISH</span> {
	<span class=palabra>ASYNC</span> {
		suma_izq = suma de la parte izquierda</span>
	}
	suma_dch = suma de la parte derecha</span>
}
suma = suma_izq + suma_dch
</pre>
<p>De este modo, si tenemos una máquina con, por ejemplo, dos procesadores,
podemos ejecutar <em>suma_izq</em> en el procesador cero y <em>suma_dch</em>
en el procesador 1.
<p>Extendiéndolo a cualquier secuencia de instrucciones, podemos utilizar
<span class=palabra>ASYNC</span> en cualquier oportunidad que encontremos
de implementar paralelismo, sincronizando los valores que necesitan estar
disponibles antes de la ejecución de otra instrucción, con
<span class=palabra>FINISH</span>.

<p>
<b>Ejercicio: calcular la suma de los elementos de un vector</b>
<br>Hacerlo primero con el algoritmo sencillo que se comenta en el texto para,
a continuación, probar a hacerlo dividendo el vector en dos partes: basta con
calcular la posición del elemento mitad (la división entera por dos de la suma
de la posición del primero y la del último); la suma de la primera parte será
desde el primer elemento hasta el mitad y la de la segunda será desde el
siguiente al elemento mitad hasta el último.
<p>
<b>Ejercicio: hacerlo ahora de forma recursiva</b>
<br>El programa sería equivalente al de la ordenación rápida (éste es más
sencillo), pero solo interesa determinar el método para realizar la suma.
Consiste en crear una función que devuelva el valor de la suma de algunos de
los elementos del vector, desde una posición de inicio a otra final:
<ul>
	<li>Si el vector no tiene elementos (la posición final es menor que
		la inicial), la suma será cero; este caso no debería darse
		nunca.
	<li>Si solo hay un elemento (las posiciones inicial y final coinciden),
		la suma será el valor del elemento.
	<li>Si hay más elementos, se calcula el elemento mitad y se determinan
		las sumas parciales invocando a la función con los nuevos
		valores: inicio y mitad, siguiente a mitad y final.
</ul>
<p>Nota: El caso en el que el vector solo contiene un elemento es el caso
base y cuando hay más, el caso general.
			</section>
			<section id=FJFrameWork>
				<header>
					<h1 id=fjframework><em>Fork-Join Framework</em></h1>
				</header>
<p>Como decíamos, los algoritmos recursivos son más ineficientes que sus
homólogos iterativos pero, en un ambiente de paralelismo, la recursividad
puede ser elegante y también eficiente. En un entorno paralelo, la
recursividad proporciona un estilo natural de describir algoritmos sin las
desventajas que se producen en la computación secuencial.
<p>El <i>framework <b>fork-join</b></i> es uno de los modos más populares de
explotar el paralelismo de Java. Se basa, fundamentalmente, en las clases
<a class=clase target=_blank href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/RecursiveAction.html>RecursiveAction</a>
y
<a class=clase target=_blank href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/RecursiveTask.html>RecursiveTask</a>.
Ambas son extensiones de una clase
<a class=clase target=_blank href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/ForkJoinTask.html>ForkJoinTask</a>,
cuya documentación podéis consultar, que permite resolver problemas mediante
la técnica de divide y vencerás, de forma eficiente, explotando el paralelismo.
La forma más simple de utilización es a través de los métodos:
<ul>
<li><span class=metodo>compute</span>, en el que construimos el algoritmo
recursivo,
<li><span class=metodo>fork</span>, con el que crearemos procesos
asíncronos (equivalente al <span class=palabra>ASYNC</span>),
<li>y <span class=metodo>join</span>, con el que esperaremos a la finalización
del proceso asíncrono (equivalente al <span class=palabra>FINISH</span>).
</ul>
<p>Siguiendo con nuestro ejemplo para la suma de los elementos de un vector,
creamos una clase Suma que contiene, como componentes de estado, un vector
<em>v</em> y unos valores de inicio (<em>izq</em>) y de finalización
(<em>dch</em>). También, un valor <em>suma</em> que almacenará la suma de
los elementos del vector desde <em>izq</em> hasta <em>dch</em>. Es decir,
el vector puede contener muchos elementos pero a nosotros solo nos
interesará aquí la suma desde un elemento cualquiera (cuya posición en el
vector denominamos <em>izq</em>) hasta otro (cuya posición denominamos
<em>dch</em>).
<pre class=code>
class Suma {
	double[] v;
	int izq, dch;
	double suma;
}
</pre>
<p>Podemos tener un constructor que almacene los valores del vector, posición
de inicio y fin. Podríamos hacer que este constructor calculara el valor de
la suma pero, en su lugar, vamos a crear un método específico.
<pre class=code>
Suma ( double[] v, int izq, int dch );
</pre>
<p>El método con el que vamos a calcular el valor de la suma (de manera
recursiva) se va a denominar <span class=metodo>compute</span>. ¿Cuál es
nuestro caso base? Recordando el ejercicio anterior, si ambos valores (de
posición) son el mismo, la suma corresponderá al valor del elemento en esa
posición.
¿Cuál es el método recursivo? Dividir el vector en dos subvectores
y calcular la suma para cada uno de ellos.
Para hacerlo, calculamos el valor de la posición intermedia <em>m</em>: la
parte izquierda irá desde la posición inicial (<em>izq</em>) hasta esta
posición intermedia (<em>m</em>); la parte derecha comenzará en la posición
siguiente a la intermedia (<em>m+1</em>) y terminará en la posición final
(<em>dch</em>).
<pre class=code>
void compute() {
	if ( izq == dch )
		suma = vector[izq];
	else {
		int m = (izq + dch) / 2;
	}
}
</pre>
<p>Volvemos a tener el mismo caso que estábamos construyendo pero con dos
secciones diferentes del vector: creamos dos nuevas instancias (<em>I</em>,
<em>D</em>) iguales a la que contiene este método, con sus respectivos
valores de inicio y fin. Ejecutamos a continuación el método compute para
cada una de esas instancias y la suma de este objeto será igual la suma de
las correspondientes a cada instancia I y D.
<pre class=code>
Suma I = new Suma(v, izq, m);
Suma D = new Suma(v, m+1, dch);
I.compute();
D.compute();
suma = I.suma + D.suma;
</pre>
<p>Como ya quedó claro, el cálculo de la suma de la parte izquierda es
totalmente independiente de la suma de la parte derecha, por lo que podemos
calcular ambas de manera asíncrona. Esto nos permite pensar que, por ejemplo,
podríamos realizar el cálculo de la suma de <em>I</em> de forma asíncrona
(<span class=palabra>ASYNC</span> I.compute();): se ejecutaría en otro
procesador si nuestra máquina es multiprocesador. Pero debemos esperar a
que dicha suma se haya realizado antes de utilizarla, junto con la de
<em>D</em>, por lo que deberá existir un <span class=palabra>FINISH</span>
que englobe a ambos compute. Finalmente, como ambas instancias habrán
calculado su propia suma, podremos obtener la suma de este objeto.
<pre class=code>
void compute() {
	if ( izq == dch )
		suma = vector[izq];
	else {
		int m = (izq + dch) / 2;
		Suma I = new Suma(v, izq, m);
		Suma D = new Suma(v, m+1, dch);
		<span class=palabra>FINISH</span> {
			<span class=palabra>ASYNC</span> {
				I.compute();
			}
			D.compute();
		}
		suma = I.suma + D.suma;
	}
}
</pre>
<p>Convetirlo en código Java es sencillo haciendo uso del
<em>FJ Framework</em>. Nuestra clase no cambia, salvo porque debe extender
a la clase
<a class=clase target=_blank href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/RecursiveAction.html>RecursiveAction</a>.
Como ya se ha comentado, el equivalente al <span class=palabra>ASYNC</span>
lo encontramos en el método <span class=metodo>fork</span>. La invocación al
método <span class=metodo>fork</span> de la clase que extiende a
<span class=clase>RecursiveAction</span> crea una nueva instancia de ejecución
que invoca la ejecución del método <span class=metodo>compute</span>. Después,
para esperar a que dicho valor esté disponible, invocamos al método
<span class=metodo>join</span> de la clase: si la ejecución de
<span class=metodo>compute</span> ya hubiera terminado, continuará la
ejecución pero, en caso contrario, bloqueará la ejecución del proceso
actual hasta que el otro proceso finalice: hasta que termine la ejecución
del <span class=metodo>compute</span> de <em>I</em>.
<pre class=code>
class Suma <span class=modificado>extends RecursiveAction</span> {
	double[] v;
	int izq, dch;
	double suma;
 	void compute() {
		if ( izq == dch )
			suma = vector[izq];
		else {
			int m = (izq + dch) / 2;
			Suma I = new Suma(v, izq, m);
			Suma D = new Suma(v, m+1, dch);<span class=modificado>
			I.fork();
			D.compute();
			I.join();</span>
			suma = I.suma + D.suma;
		}
	}
}
</pre>
<p>En lugar de utilizar el par <em>fork-join</em>, resulta posible también
utilizar el método
<a class=metodo href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/ForkJoinTask.html#invokeAll(java.util.concurrent.ForkJoinTask,java.util.concurrent.ForkJoinTask)>invokeAll</a>,
que se encarga por si mismo de lanzar la ejecución de ambas tareas y esperar
a su finalización, antes de proseguir.
<pre class=code>
...
Suma I = new Suma(v, izq, m);
Suma D = new Suma(v, m+1, dch);<span class=modificado>
invokeAll(I, D);</span>
suma = I.suma + D.suma;
...
</pre>
<p>Tal cual lo hemos creado hasta este momento, el programa es totalmente
funcional y, si creamos un objeto de nuestra
clase <em>Suma</em> e invocamos su método <em>compute</em>, éste se
ejecutará haciendo uso del paralelismo.
<pre class=code>
import java.util.concurrent.RecursiveAction;

public class SumaVector {

	static final int MAX_VECTOR = 1000000;

	static class SumaFJ extends RecursiveAction {
		double suma;
		int ini, fin;
		double[] vector;
		
		SumaFJ ( double[] v, int i, int f ) {
			vector = v;
			ini = i;
			fin = f;
		}
		
		 protected void compute ( ) {
			if ( ini == fin ) suma = vector[ini];
			else {
				int mitad = (ini + fin) / 2;
				SumaFJ izq = new SumaFJ(vector, ini, mitad);
				SumaFJ dch = new SumaFJ(vector, mitad+1, fin);
				izq.fork(); dch.compute(); izq.join();
				suma = dch.suma + izq.suma;
			}
		}
	}
	
	public static void main ( String[] args ) {
		double[] vector = new double[MAX_VECTOR];
		for ( int i = 0; i < MAX_VECTOR; i++ )
			vector[i] = Math.random();
		SumaFJ aux = new SumaFJ(vector, 0, vector.length-1);
		aux.compute();

	}
}
</pre>
<p>El <em>framework fork-join</em> se ejecuta, por defecto, en un servicio
de ejecución denominado
<a class=clase target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/ForkJoinPool.html>ForkJoinPool</a>.
No vamos, de momento, a entrar en cómo funciona. Nos basta con pensar que
hay un servicio con el que vamos a poder trabajar. Podemos también utilizarlo,
explícitamente: en algún punto de nuestro código invocaremos una instancia
de la clase que extiende el <span class=clase>RecursiveAction</span> como
muestra el código siguiente:
<pre>
class Programa {
    ...
    class Ejemplo extends RecursiveAction {
        ...
    }
    ...
        ForkJoinPool
	    .commonPool()
            .invoke(ra = new Ejemplo(...));
        // obtenemos ra.valor
    ...
    main( ) {
        ...
    }
}
</pre>
<p>Este <span class=clase>ForkJoinPool</span> tiene un método
<span class=metodo>commonPool</span> que nos devuelve una referencia
al grupo de hilos estándar, apropiado para la mayoría de las aplicaciones.
Podemos también enviar nuestra tarea, con el método
<span class=metodo>invoke</span> para que la ejecute en paralelo.
<p>Estamos creando una clase que almacena un valor, <em>suma</em> para
poderlo obtener más adelante. ¿Sería posible que <em>compute</em>, en lugar
de un procedimiento, fuera una función? Si <em>compute</em> fuera una función
recursiva sería muy sencillo algo como:
<br><span class=code>return I.compute() + D.compute();
<p>En el modelo de <em>FJ Framework</em> supondría que, de algún modo, ambas
funciones deberían ejecutarse en paralelo, esperando a que ambos resultados
estuvieran disponibles para realizar la suma a continuación. Esto tiene que
ver con un concepto que se verá en el capítulo 5: el futuro o promesa. En
cualquier caso, el <i>framework</i> nos proporciona un método sencillo de
implementación de esta posibilidad. Nuestra clase no cambia, salvo porque
debe extender a la clase
<a class=clase target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/RecursiveTask.html>RecursiveTask</a>,
en lugar de a <span class=clase>RecursiveAction</span>. El método compute
se transforma ahora en una función que devuelve un tipo de datos determinado.
Como antes, podemos invocar <span class=metodo>fork</span> para la ejecución
asíncrona y esperamos a que dicho valor esté disponible invocando al método
<span class=metodo>join</span>.
<pre class=code>
class Suma extends <span class=modificado>RecursiveTask&lt;Double&gt;</span> {
	double[] v;
	int izq, dch;
	<span class=modificado>// double suma; Innecesario</span>
 	<span class=modificado>Double</span> compute() {
		if ( izq == dch )
			<span class=modificado>return</span> vector[izq];
		else {
			int m = (izq + dch) / 2;
			Suma I = new Suma(v, izq, m);
			Suma D = new Suma(v, m+1, dch);
			I.fork();
			<span class=modificado>return D.compute() + I.join();</span>
		}
	}
}
</pre>
<p>Vemos, en primer lugar, que <span class=clase>RecursiveTask</span> es
una clase genérica y, por tanto, asignamos la clase de datos con los que
va a trabajor al crearla: en este caso, <span class=clase>Double</span>.
A continuación, hemos eliminado el atributo <em>suma</em>, al resultar
innecesario: el valor es devuelto por la función. Finalmente, la ventaja
de utilizar este <i>framework</i> es que la propia clase gestiona la
utilización de un futuro, que nos devuelve con el método
<span class=metodo>join</span>: tomará el valor de
<span class=metodo>compute</span> cuando esté disponible. Podemos apreciar
como, como antes, lanzamos la tarea para <em>I</em> pero ahora, en lugar de
esperar tras la ejecución de la de <em>D</em>, podemos especificar la suma
directamente, que no se realizará hasta que ambos valores estén disponibles.
<p>Este ejemplo que estamos viendo es muy simple ya que solo genera dos
tareas cada vez que se ejecuta: creamos una nueva instancia con
<span class=metodo>fork</span> y la actual invoca
<span class=metodo>compute</span>. También podríamos crear dos instancias y
esperar a que ambas finalizaran. En ese caso, es más eficiente esperar la
finalización en orden inverso al que han sido creadas:
<br><span class=code>I.fork(); D.fork(); D.join(); I.join();
<p>Si, por ejemplo, tuviéramos tres tareas, deberíamos, al menos, crear dos
instancias con <span class=metodo>fork</span> y que la tercera ejecutara el
<span class=metodo>compute</span>, aunque también podríamos crear tres
instancias. Si el número de tareas es mayor, podemos, por ejemplo utilizar
colecciones para almacenar esas tareas y lanzar, automáticamente, las
instancias que sean necesarias con <span class=metodo>invokeAll</span>.
Finalmente, recuperaremos sus valores con <span class=metodo>join</span>.
<pre class=code>
class Ejemplo extends RecursiveTask&lt;T&gt; {
	...
	Ejemplo (...) { ... }
	...
	protected T compute() {
		ArrayList&lt;RecursiveTask&lt;T&gt;&gt; al =
			 new ArrayList&lt;RecursiveTask&lt;T&gt;&gt;();
		for ( int i = 0; i &lt; x; i++ ) {
			...
			al.add(new Ejemplo(params))
		}
		try {
			invokeAll(al);
			...
			for ( RecursiveTask&lt;T&gt; rt: al ) {
				operación con rt.join();
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
	}
}
</pre>
<p>Finalizamos este apartado comentado la forma en que el servicio de
ejecución trabaja. Dispone de un conjunto de hilos, de manera que todos
ellos intentan encontrar tareas, lanzadas con <span class=metodo>fork</span>,
<span class=metodo>invokeAll</span>... y ejecutarlas; es decir, que cada hilo
puede ejecutar más de una tarea. Por defecto, el número de hilos será igual
al de procesadores que tenga el sistema. Podemos, no obstante, indicar
cuántos hilos deseamos que sean utilizados en el constructor del servicio:
<a class=clase target=_blank
   href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/ForkJoinPool.html#%3Cinit%3E(int)>ForkJoinPool(int parallelism)</a>,
haciendo uso del mismo como indica el código siguiente:
<pre class=code>
    ...
ForkJoinPool ejecutor;
    ...
ejecutor = new ForkJoinPool(NÚMERO_DE_HILOS);
    ...
ejecutor.invoke(<i>instancia Recursive...</i>);
    ...
ejecutor.shutdown();
    ...
</pre>
<p>El método <a class=clase target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/concurrent/ForkJoinPool.html#shutdown()>shutdown</a> no tiene
efecto alguno cuando trabajamos con el <em>commonPool</em> pero, en este caso,
es necesario para llevar a cabo una finalización ordenada de las tareas.
			</section>
			<section id=Amdhal>
				<header>
					<h1 id=amdhal>Ley de Amdhal</h1>
				</header>
<p>
Suponemos que tenemos una secuencia de acciones: S1, S2, S3, S4; de manera
que S2 y S3 pueden ejecutarse de forma asíncrona. Siguiendo el pseudocódigo
que hemos visto, podemos representarlo con un <span class=palabra>ASYNC</span>
de S2 y un <span class=palabra>FINISH</span> que engloba a S2 y S3:
<span class=code>
	S1 -       S1
	S2 - ASYNC S2
	S3 -       S3
	     FINISH
	S4 -       S4
</span>
lo represento sin llaves pero significa igualmente que S2 se ejecutará de
forma asíncrona y esperaremos a la finalización (de lo que precede) antes
de que se ejecute S4. En el formato que hemos visto en Java, podemos
representarlo con el par Fork-Join, asumiendo que S2 fuera una
<span class=clase>ForkJoinTask</span>:
<span class=code>
        S1 -       S1 - S1
        S2 - ASYNC S2 - S2.fork()
        S3 -       S3 - S3
             FINISH   - S2.join()
        S4 -       S4 - S4
</span>
<p>Vamos ahora a introducir un concepto denominado grafo computacional: un
grafo dirigido cuyos nodos se corresponden con operaciones matemáticas; en
nuestro caso, cada nodo se corresponderá con una de las operaciones
secuenciales. A nosotros va a servirnos para modelar la ejecución en paralelo.
El grafo es solo una abstracción que nos ayuda a pensar en el programa
ejecutándose dinámicamente. En líneas generales, un grafo es una
representación gráfica de nodos (o vértices), elementos que componen el
gráfico, ejes (o aristas), líneas que unen los nodos, y caminos, conjunto
de nodos unidos por ejes.
<p>Así, empezamos por el nodo S1: lo representamos rodeando S1 en un círculo.
A continuación, si nos fijamos en la versión FJ, se produce un <em>FORK</em>
a S2: lo representamos con una flecha (y lo denominamos eje fork); la flecha
indica que es dirigido: solo va de S1 a S2. Y justo a continuación del mismo,
S1 continúa a S3 (eje continuar); y S3 continúa a S4. Pero existe un
<em>JOIN</em>, por lo que tenemos un nuevo eje (que denominamos join) de S2 a
S4. De este modo, con estos tres ejes, fork, join, y continuar, podemos
modelar la ejecución de nuestro programa paralelo. Si no tuviéramos los nodos
fork y join, nuestro grafo sería una línea secuencial con ejes continuar.
<div class=image id=img_04_01>
	<img src=imagenes/04_01_grafo.png style="width: 15em"
	     alt="Grafo computacional con ejes fork, join y continuar">
	<p class=caption>Grafo computacional de las tareas
</div>
<p>Una propiedad del grafo es que nos permite razonar qué instrucciones
pueden ejecutarse en paralelo: ¿Existe un camino  dirigido de un nodo a
otro? Por ejemplo, hay un camino ente S2 y S4: S2 y S4 no pueden ejecutarse
en paralelo. De forma análoga, como no hay caminos entre S2 y S3, es posible
la ejecución en paralelo.
<p>
Otra propiedad muy interesante de los grafos computacionales es que nos
permiten razonar acerca del rendimiento del programa paralelo. El rendimiento,
normalmente, se mide como una frecuencia de eventos por unidad de tiempo, ya
que tiempo más bajo significa mayor rendimiento. Pero tendemos a hablar de
rendimiento como tiempo o velocidad, incluyendo términos como mejora, en
lugar de utilizar mayor (velocidad) o menor (tiempo).
<p>Nosotros vamos a utilizar, como coste, un número asociado al tiempo: mayor
coste, menor rendimiento. Imaginemos que el coste de ejecución de S1 es 1,
los de S2 y S3, 10, y el S4, 1. Utilizamos dos métricas: trabajo 
(<span class=palabra>work</span>) y duración
(<span class=palabra>span</span>); el primero corresponde al coste total y el
segundo al coste del camino más largo. A partir de estas métricas construimos
la idea de <b>paralelismo ideal (<em>IP</em>)</b> como el trabajo dividido
por la duración.
<p>Así, el trabajo será la suma de los tiempos de ejecución de todas las
tareas: <span class="font-family:monospace">1+10+10+1=22</span>. Para el
cálculo de la duración tenemos dos caminos:
<span class="font-family:monospace">S1 -> S2 -> S4</span> y
<span class="font-family:monospace">S1 -> S3 -> S4</span>; en ambos casos,
el coste es
<span class="font-family:monospace">1+10+1=12</span>.
<p>En este caso, el paralelismo ideal es muy pequeño:
<math xmlns="http://www.w3.org/1998/Math/MathML">
	<mrow>
		<mi>IP</mi>
		<mo>=</mo>
		<mfrac>
			<mrow>
				<mi>W</mi>
			</mrow>
			<mrow>
				<mi>S</mi>
			</mrow>
		</mfrac>
		<mo>=</mo>
		<mfrac>
			<mrow>
				<mn>22</mn>
			</mrow>
			<mrow>
				<mn>12</mn>
			</mrow>
		</mfrac>
	</mrow>
</math>
, que apenas llega a 2; pero hay que tener en cuenta que en un programa
secuencial es 1, ya que el trabajo es igual a la duración.
<div style="width:80%;margin-left:10%;">
	<p><b>La mejora en el rendimiento de un sistema está limitada por la
	fracción de tiempo que (dicho sistema) pueda ser más rápido.</b>
</div>
<p>La
<a target=_blank href=https://es.wikipedia.org/wiki/Ley_de_Amdahl>ley de Amdhal</a>
define la ganancia de rendimiento o aceleración (<i><b>speedup</b></i>) que
puede lograrse al utilizar una característica determinada del sistema, que
es más rápida que la original. La aceleración es la relación entre el
rendimiento de la tarea usando la mejora y el rendimiento sin usarla o,
alternativamente, el tiempo de ejecución sin usar la mejora dividido por el
tiempo de ejecución usando la mejora:
<p>
<math xmlns="http://www.w3.org/1998/Math/MathML">
	<mrow>
		<mtext>Aceleración</mtext>
		<mo>=</mo>
		<mfrac>
			<mrow>
				<mtext>
Trabajo (coste) de la tarea sin utilizar la mejora
				</mtext>
			</mrow>
			<mrow>
				<mtext>
Trabajo (coste) de la tarea utilizando la mejora cuando sea posible
				</mtext>
			</mrow>
		</mfrac>
	</mrow>
</math>
<p>Vamos a tratar de ver ahora cómo la Ley de Amdhal se aplica a lo que hemos
contado.
<p>Supongamos que tenemos una serie de tareas S1...S7, que siguen el grafo
computacional de la figura. Algo interesante del grafo es que no nos importa
de dónde vienen los ejes o si son de uno u otro tipo. Pero podemos pensar en
su rendimiento; imaginemos que todas las tareas tienen un coste 1, excepto S6,
que tiene un coste 10. Estamos interesados en la idea del tiempo de ejecución
<em>T</em> en <em>P</em> procesadores, <em>T<sub>P</sub></em>.
<p>Vamos a pensar cómo estas instrucciones del grafo computacional son
planificadas en los procesadores. Supongamos que disponemos de una máquina
con dos procesadores. El planificador hará que las instrucciones se repartan
entre ambos: tras la ejecución de S1, el primer procesador podría ejecutar S2
y S3, mientras que el segundo ejecutaría S4 y S5. A continuación, el primer
procesador ejecutaría S6 y, finalmente, se ejecutaría S7.
<p>Como vemos, con esta planificación, <em>T<sub>2</sub> = 14</em>. Los instantes en
que el segundo procesador no está ejecutando instrucciones se denominan
<span class=palabra>IDLE</span> (ocioso); uno de los objetivos de la
paralelización es reducir al mínimo el tiempo en que el procesador permanece
ocioso.
<p>Una planificación más interesante se produciría si se tuviera conocimiento
de que S6 tiene un coste superior y se diera prioridad a su ejecución, para
que lo hiciera lo antes posible. De este modo, tras la ejecución de S1, el
primer procesador podría ejecutar S6, mientras que el segundo ejecutaría S2 y
S3, así como S4 y S5; el orden en que se ejecuten, empezando por S2 o por S4,
es irrelevante, siempre que se garantice que S2 se ejecuta antes que S3 y que
S4 lo hace antes que S5. A continuación, el primer procesador ejecutaría S7 y
finalizaría. Con esta planificación, <em>T<sub>2</sub> = 12</em>.
<p>Esta definición del tiempo de ejecución en <em>P</em> procesadores, depende
de la planificación, pero podemos determinar algunas propiedades. Primero,
¿qué sucede si <em>P = 1</em>? Podemos asegurar que <em>T<sub>1</sub> =
<span class=palabra>WORK</span></em>, que en este caso, es 16. Análogamente,
si tuviéramos un número infinito de procesadores, <em>T<sub>&#x221e;</sub> =
<span class=palabra>SPAN</span></em>, que en este caso es 12.
<p>De este modo, dado un número de procesadores <em>P</em>, podemos asegurar
que <em>T<sub>&#x221e;</sub> &lt;= T<sub>P</sub> &lt;= T<sub>1</sub></em>. Y
que la aceleración que obtenemos es la relación entre <em>T<sub>1</sub></em>
y <em>T<sub>P</sub></em>, que coincide con el enunciado de la <b>ley de
Amdahl</b>, que antes veíamos. De donde deducimos fácilmente que la
<em>aceleración</em> es, obligatoriamente, menor o igual que <em>P</em>; y que
es menor o igual que el <em>paralelismo ideal</em>. Es decir, está limitada
por el número de procesadores de que disponemos pero, más importante, también
por el paralelismo ideal del grafo computacional.
<p>Nuestro objetivo al diseñar algoritmos paralelos es el de generar gráficos
computacionales con un paralelismo ideal mayor que el número de procesadores
disponible.
<p>Cuando creamos una nueva instancia de ejecución, como ya se indicó al
comparar la creación de procesos e hilos, se produce una sobrecarga de
código, código que no pertenece a nuestro programa. Es decir, aunque
dividamos el tiempo de ejecución por la mitad, ese tiempo será un poco mayor
por los recursos dedicados a crear la/s instancia/s de ejecución.
<p><em>¡Atención! Las ecuaciones mostradas a continuación no pretenden ser un
	desarrollo matemático; solo una forma de explicar el concepto que se
	desea introducir. Y para el que hacemos uso del <i>FJ Framerowk</i>,
	que ya conocemos.</em>
<p>Para un tiempo de ejecución <em>T</em>, al aplicar paralelismo, tendremos
un tiempo de ejecución
<math xmlns="http://www.w3.org/1998/Math/MathML">
	<mrow>
		<mfrac>
			<mrow>
				<mi>T</mi>
			</mrow>
			<mrow>
				<mn>2</mn>
			</mrow>
		</mfrac>
		<mo>+</mo>
		<mi>X</mi>
	</mrow>
</math>
, suponiendo que lo dividimos por 2 y <em>X</em> es el tiempo que el sistema
requiere para que ello sea posible. En una nueva ejecución, ese tiempo sería
<math xmlns="http://www.w3.org/1998/Math/MathML">
	<mrow>
		<mfrac>
			<mrow>
				<mi>T</mi>
			</mrow>
			<mrow>
				<mn>4</mn>
			</mrow>
		</mfrac>
		<mo>+</mo>
		<mn>3</mn>
		<mi>X</mi>
	</mrow>
</math>
y así, sucesivamente, hasta llegar a hacer <em>n</em> particiones:
<math xmlns="http://www.w3.org/1998/Math/MathML">
	<mrow>
		<mfrac>
			<mrow>
				<mi>T</mi>
			</mrow>
			<mrow>
		<!--	<mroot> 2 n </mroot> -->
		<msup>
			<mn>2</mn>
			<mi>n</mi>
		</msup>
			</mrow>
		</mfrac>
		<mo>+</mo>
		<mo>(</mo>
		<!--	<mroot> 2 n </mroot> -->
		<msup>
			<mn>2</mn>
			<mi>n</mi>
		</msup>
		<mo>-</mo>
		<mn>1</mn>
		<mo>)</mo>
		<mi>X</mi>
	</mrow>
</math>
. Podemos realizar el mismo desarrollo calculándolo para 3 particiones

<table border id=tabla_04_01>
	<thead>
		<tr>
			<th>Particiones</th>
			<th colspan=2>Tiempo</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>0</td>
			<td>T</td>
			<td>T</td>
		</tr>
		<tr>
			<td>1</td>
			<td>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <mn>2</mn>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mi>X</mi>
        </mrow>
</math>
			</td>
			<td>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <mn>3</mn>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mn>2</mn>
                <mi>X</mi>
        </mrow>
</math>
			</td>
		</tr>
		<tr>
			<td>2</td>
			<td>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <mn>4</mn>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mn>3</mn>
                <mi>X</mi>
        </mrow>
</math>
			</td>
			<td>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <mn>9</mn>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mn>8</mn>
                <mi>X</mi>
        </mrow>
</math>
			</td>
		</tr>
		<tr>
			<td>3</td>
			<td>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <mn>8</mn>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mn>7</mn>
                <mi>X</mi>
        </mrow>
</math>
			</td>
			<td>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <mn>27</mn>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mn>26</mn>
                <mi>X</mi>
        </mrow>
</math>
			</td>
		</tr>
		<tr>
			<td colspan=3>
				...
		</tr>
		<tr>
			<td>n</td>
			<td>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <msup>
                                        <mn>2</mn>
                                        <mi>n</mi>
                                </msup>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mo>(</mo>
                <msup>
                        <mn>2</mn>
                        <mi>n</mi>
                </msup>
                <mo>-</mo>
                <mn>1</mn>
                <mo>)</mo>
                <mi>X</mi>
        </mrow>
</math>
			</td>
			<td>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <msup>
                                        <mn>3</mn>
                                        <mi>n</mi>
                                </msup>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mo>(</mo>
                <msup>
                        <mn>3</mn>
                        <mi>n</mi>
                </msup>
                <mo>-</mo>
                <mn>1</mn>
                <mo>)</mo>
                <mi>X</mi>
        </mrow>
</math>
			</td>
		</tr>
	</tbody>
</table>

<p>Y, en general, para un algoritmo que realiza <em>p</em> divisiones en cada
ejecución, tendremos que su tiempo de ejecución vendrá dado por:
<p>
<math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
                <mfrac>
                        <mrow>
                                <mi>T</mi>
                        </mrow>
                        <mrow>
                                <msup>
                                        <mi>p</mi>
                                        <mi>n</mi>
                                </msup>
                        </mrow>
                </mfrac>
                <mo>+</mo>
                <mo>(</mo>
                <msup>
                        <mi>p</mi>
                        <mi>n</mi>
                </msup>
                <mo>-</mo>
                <mn>1</mn>
                <mo>)</mo>
                <mi>X</mi>
        </mrow>
</math>
<p>De esa fórmula, podemos deducir, fácilmente, que, para algún número de
divisiones, el tiempo que se necesita para que el sistema disponga los
recursos necesarios para paralelizar es igual o mayor que el tiempo necesario
para que se ejecute secuencialmente, por lo que es preferible ejecutarlo de
forma secuencial. El <b>umbral paralelo</b> será una cantidad que represente
el número de elementos, u otra característica, a partir de la cual
obtengamos mejora al paralelizar, por lo que, cuando no se dé esa
condición, ejecutaremos el algoritmo secuencial:
<pre class=code>
final int UMBRAL_PAR = Valor a partir del que palelizamos
...
if ( número <= UMBRAL_PAR ) {
    // ejecuta operación secuencial
} else {
    // ejecuta operación Fork-Join
}
</pre>
<p>En nuestro algoritmo de la suma de los elementos de un vector, por ejemplo,
el umbral paralelo puede ser el número de elementos del vector, es decir,
<em>dch - izq</em>. De ese modo, si el número de elementos es igual o menor
que aquél para el que hemos determinado que obtendremos beneficio al
paralelizarlo, realizaremos la suma de forma secuencial.

			</section>
			<section id=Streams>
				<header>
					<h1 id=streams>Streams en Java</h1>
				</header>

<h2>Función Lambda</h2>
<p>Las funciones lambda, también denominadas
<a href=https://es.wikipedia.org/wiki/Expresi%C3%B3n_lambda>expresiones lambda</a>
o función anónima, son funciones que se definen pero no se les asigna un
nombre porque se utilizan solo una vez o un número de veces limitado. Tienen
múltiples usos, dependiendo del lenguaje de programación y la forma de
implementación de las mismas, aunque podríamos destacar, como los más
comunes, la generación de funciones patrón o la utilización como parámetros
de otras funciones como, por ejemplo, las de ordenación: el método de
ordenación es desconocido hasta la invocación de la función, pudiendo
generar esa función en el parámetro actual, como función anónima.
<p>Su <a href=https://docs.oracle.com/javase/specs/jls/se14/html/jls-15.html#jls-15.27>sintaxis</a>
en <a href=https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html>Java</a>
es sencilla: se indica la lista de parámetros, separados por comas, entre
paréntesis, seguidos del símbolo de la flecha (el guión y el símbolo de
mayor que, en ese orden), finalizando con el cuerpo de la función. Resulta
posible suprimir los paréntesis si solo hay un parámetro (o poner solo los
paréntesis si no los hay) y no es necesario indicar el tipo de datos de los
argumentos, ya que el compilador puede inferirlos por el contexto. El cuerpo
de la función puede ser una expresión simple, devolviendo el resultado de
evaluar dicha expresión –que puede ser de tipo void y no devolver nada-, o
puede ser como el cuerpo de cualquier otro método: encerrando en un bloque
(entre llaves) con las instrucciones separadas por puntos y comas; si queremos
que devuelva un valor, deberemos utilizar return.
<p>En
<a href=https://es.wikipedia.org/wiki/Expresi%C3%B3n_lambda#Java>Wikipedia</a>
podéis encontrar una serie de ejemplos de funciones lambda. El último ejemplo
del primer bloque, el de
<span class=code style="margin-left:0">(id, defaultPrice)</span>, contiene
expresiones asociadas a un <em>stream</em>, objeto de esta sección. Es
importante tener en cuenta que puede declarar variables locales pero también
que tiene acceso a las variables declaradas en los bloques que engloban a la
función lambda. Sin embargo, no puede modificar sus valores: puede utilizarse
una variable local que sea una referncia.

<h3>Interfaz funcional</h3>
<p>Las funciones lambda no están pensadas para ejecutarse por sí mismas: se
utilizan para implementar un método definido por un interfaz funcional. Un
<b>interfaz funcional</b> es aquél que contiene un método abstracto y solo
uno. Eso significa que representa una única acción.
<p>El interfaz funcional define el objetivo de la función lambda; a veces, es
denominado SAM (Single Abstract Method).
<p>Aquí podemos ver un ejemplo de interfaz funcional:
<pre class=code>
interface miNumero {
	double elNumero();
}
</pre>
<p>El método <span class=metodo>elNumero</span>() es abstracto de forma
implícita y es el único método de <span class=clase>miNumero</span>: es un
interfaz funcional.
<p>Como ya hemos comentado, las funciones lambda no están pensadas para
ejecutarse por sí mismas, sino que constituyen la implementación del método
abstracto definido por el interfaz funcional. Veamos cómo podemos utilizar la
expresión lambda para asignar contexto a una referencia al interfaz funcional.
Creamos un objeto del tipo del interfaz y le asignamos una función lambda:
<pre class=code>
miNumero numero;
miNumero = () -> 1.23;
</pre>
<p>¿Qué sucede ahora si utilizamos el objeto o, más propiamente, su
<em>método abstracto único</em>?
<pre class=code>
System.out.println("Número fijo: " + numero.elNumero());
</pre>
<p>Ese código imprimirá <em>Número fijo: 1.23</em>.
<p>Podemos también, por ejemplo, asignar una función diferente al método:
<pre class=code>
miNumero = () -> Math.random() * 50;
System.out.println("Núm. aleat.: " + numero.elNumero());
System.out.println("Otro aleat.: " + numero.elNumero());
</pre>
<p>Pero, si la función lambda devolviera una cadena de texto, generaría un
error de tipo porque el método abstracto devuelve un número en punto
flotante de doble longitud.
<pre class=code>
miNumero = () -> "Error de tipo";
</pre>
<p>También sería un error si la expresión lambda tomara parámetros.

<h3>Referencia a método</h3>
<p>Cuando se utiliza una función lambda para invocar un método ya existente,
resulta más simple invocar directamente a dicho método, sin necesidad de
crear la función lambda. La forma de hacerlo es mediante la utilización del
operador <em>::</em> (dos puntos seguido de dos puntos). Pero cuidado, la
referencia a método es una expresión lambda, no puede utilizarse con
cualquier método.
<p>Supongamos la clase de ejemplo:
<pre class=code>
class MiClase {
	static int metodoEstatico ( parametrosFormales ) {
		// Cuerpo del método
	}
}
</pre>
<p>En lugar de escribir la función lambda:
<br><span class=code>( parametrosActuales ) -> MiClase.metodoEstatico(parametrosActuales)</span>
<br>los métodos estáticos de clase se transforman en la siguiente referencia
a método:
<br><span class=code>MiClase::metodoEstatico</span>
<p>Los métodos de instancia hacen referencia a un objeto conocido, del mismo
modo que cuando se utiliza con la clase. La diferencia en este caso es que
invocamos al método no estático, desde el identificador del objeto.
<p>Las referencias a métodos de instancia de un objeto particular son aquellas
en los que vamos a aplicar nuestra función lambda a varios objetos del mismo
tipo o clase. Si suponemos que tenemos un objeto del tipo ClaseDelObjeto, la
expresión:
<br><span class=code>( objeto, parametrosActuales ) -> objeto.metodo(parametrosActuales)</span>
<br>puede ser reemplazada por:
<br><span class=code>ClaseDelObjeto::metodo</span>
<p>Un ejemplo simple es el que aparece en el <a target=_blank
href=https://docs.oracle.com/javase/tutorial/java/javaOO/methodreferences.html>tutorial</a> de Java:
<pre class=code>
String[] stringArray = { "Barbara", "James", "Mary", "John", "Patricia", "Robert", "Michael", "Linda" };
Arrays.sort(stringArray, String::compareToIgnoreCase);
</pre>
<p>La referencia al constructor es muy similar a la referencia a un método
estático, con la diferencia de que el nombre del método es <em>new</em>. Lo
que hace esta función lambda es crear un nuevo objeto y referenciar a un
constructor de la clase.

<aside>
Si quieres saber más sobre las funciones lambda, además del tutorial de Java,
puedes visitar la página <a target=_blank
href=http://www.lambdafaq.org/>Maurice Naftalin's Lambda FAQ</a>.
</aside>

<h2>Streams</h2>
<p>Los <a class=clase target=_blank
	  href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/stream/package-summary.html>Streams</a>
de Java (no los <em>Java IO Streams</em>) representan una forma de trabajar
con colecciones de datos masivos, mediante funciones de <a target=_blank
	href=https://docs.oracle.com/javase/tutorial/collections/streams/reduction.html>agregación y reducción</a>.
Un <em>stream</em> es una secuencia de elementos, objetos, que se introducen
en un <em><b>pipeline</b></em>: una secuencia de funciones u operaciones. A
diferencia de la colección, el <a class=clase target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/stream/Stream.html>stream</a>
no almacena datos, solo los transporta de una operación a otra del pipeline.
<p>Supongamos que tenemos una colección de elementos y queremos imprimirlos:
podemos utilizar un bucle <em>for</em> para imprimir cada uno de los elementos
dentro del bucle:
<pre class=code>
for ( p: coleccion )
	System.out.println(p);
</pre>
<p>Pero usando <em>stream</em>, podemos crear dicho <em>stream</em> desde la
colección y después, para cada elemento (<a class=metodo target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/stream/Stream.html#forEach(java.util.function.Consumer)>forEach</a>())
del <em>stream</em>, proporcionar una función lambda:
<pre class=code>
coleccion
	.stream()
	.forEach(System.out::println);
</pre>
<p>Un ejemplo más complicado puede ser aquél en el que queremos conocer la
media aritmética del valor de algunos de los elementos de la colección.
Empezaríamos recorriendo la colección y añadiendo los valores que cumplen la
condición a una segunda colección; a continuación, recorreríamos esa segunda
colección para ir sumando sus valores y, finalmente, calcularíamos la media
como la suma de los valores dividido por el número de elementos de la segunda
colección.
<pre class=code>
for ( p: coleccion )
	if ( p.valido() )
		validos.add(p);
for ( v: validos )
	suma += v.valor();
media = suma / validos.size();
</pre>
<p>Se puede hacer de forma más elegante con <em>streams</em>. Como antes,
crearemos el mismo desde la colección. Después, hacemos un filtrado:
utilizamos la operación <a class=metodo target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/stream/Stream.html#filter(java.util.function.Predicate)>filter</a>()
para seleccionar un conjunto de elementos y, como método de filtrado,
proporcionamos una función lambda: la función que verifica que el elemento
cumple la condición. Llegados a este punto, el stream solo contiene aquellos
elementos que cumplen la condición y necesitamos extraer el valor: hacemos una
traslación (función <a class=metodo target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/stream/Stream.html#map(java.util.function.Function)>map</a>())
para asignar al <em>stream</em> los valores de los elementos, en lugar de los
elementos de la colección. Utilizamos la función <a class=metodo target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/stream/Stream.html#mapToInt(java.util.function.ToIntFunction)>
	mapToInt</a>(),
que devuelve un <em>stream</em> de enteros (<em>Integer</em>). Por último,
para calcular la media aritmética, usamos la función
<a class=metodo target=_blank
   href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/stream/DoubleStream.html#average()>average</a>();
el valor resultado es un número que podemos asignarlo a la variable:
<pre class=code>
media = colección
	.stream()
	.filter(Clase::valido)
	.mapToInt(Clase::valor)
	.average();
</pre>
<p>NOTA: la función <em>average</em> devuelve un valor opcional de tipo
<em>real</em>, por lo que deberemos usar el método
<a class=metodo target=_blank
	href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/OptionalDouble.html#getAsDouble()>getAsDouble</a>().
<p>Resulta evidente cómo, entre las ventajas de los streams, no necesitamos
iterar de forma explícita o crear colecciones intermedias.
<p>Con los ejemplos que veíamos antes, a las funciones como <em>filter</em> se
las denomina <b>funciones intermedias</b> porque producen un nuevo stream,
mientras que las funciones como <em>forEach</em>, que no producen un stream,
se denominan <b>funciones terminales</b>.
<p>Un <em>pipeline</em> tiene que tener un origen: este puede ser un vector,
una colección, una función generadora o un flujo de <i>ES</i>. También una
serie de funciones intermedias, aunque puede no haber ninguna. Y, finalmente,
una función terminal.
<p>Funciones como <em>filter</em>, <em>mapToInt</em> o <em>average</em> son
denominadas <b>funciones de agregación</b> porque aplican la función indicada
a cada elemento del <em>stream</em>. Aunque pueden parecer iteradores, o que
se comportan como ellos, hay diferencias fundamentales. Con un iterador, el
programador determina sobre qué elementos opera y cómo opera; en los streams
(el programador) determina sobre qué objetos iterar pero es Java la que
determina cómo operar sobre ellos. Las funciones procesan elementos del
stream, no de la colección, por lo que son denominadas <b>operaciones de
<em>stream</em></b> (<em><b>stream operations</b></em>). Por último, la
mayoría de las funciones de agregación reciben como parámetro una función,
por lo que se puede adaptar el modo de trabajo de función a través de una
expresión lambda.

<h3>Paralelismo</h3>
			</section>
			<footer>
<nav class=pie>
	<a class=previo href=03_progsec.html>Programación segura</a>
        <a class=inicio href=index.html>Índice</a>
        <a class=siguiente href=05_progconc.html>Programación concurrente</a>
</nav>
		<p>Programación de servicios y procesos</p>
			</footer>
		</article>
	</body>
</html>
