<!doctype html>

<html lang=es>
	<head>
		<title>Introducción</title>
		<meta charset=utf-8>
		<meta name=author content="Antonio Cepero">
		<meta name=created content="2021-03-19">
		<meta name=modified content="2021-08-20">
		<link rel=stylesheet href="estilo.css">
	</head>
	<body>
		<article>
			<header>
				<h1>Introducción</h1>
			</header>
			<nav class=toc>
				<ol>
					<li><a href=#ejecutable>Qué es un ejecutable</a></li>
					<li><a href=#proceso>Qué es un proceso</a></li>
					<li><a href=#servicio>Qué es un servicio</a></li>
					<li><a href=#estados>Estados de un proceso</a></li>
					<li><a href=#hilos>Hilos</a></li>
					<li><a href=#tiposp>Tipos de programación</a></li>
					<li><a href=#jvm>La máquina virtual de Java</a></li>
				</ol> 
			</nav>
			<section id=Ejecutable>
				<header>
					<h1 id=ejecutable>Qué es un ejecutable</h1>
				</header>
<p>Un ejecutable es un archivo binario que la máquina reconoce como un
programa. El fichero binario se corresponderá con una secuencia de las
instrucciones
a ejecutar, escritas directamente o traducidas desde un código fuente en
un lenguaje de programación. No	obstante, para mejorar su eficiencia, el
ejecutable -una vez en la memoria de la computadora- se divide en varias
secciones o segmentos: texto, datos, montón (o montículo) y pila.
<div class=image id=img_01_01 style="width:80%; margin-left:10%">
	<img src=imagenes/01_01_ejecutable.png
	     alt="Secciones de un ejecutable: pila,
	     zona libre de memoria, montón, datos y código">
	<p class=caption>Formato de un ejecutable en memoria
</div>
<p>La sección de texto contiene el código binario propio del programa,
empezando, normalmente, en la dirección de menor valor (que podemos
considerar que fuera la dirección cero) y creciendo hasta que finaliza el
código.
A continuación, la sección de datos almacena los valores globales:
constantes y variables, inicializadas o no; en la literatura, este segmento,
podéis encontrarlo dividido en DATA (o CONST) y BSS -Block Starting Symbol-,
según estén, respectivamente, inicializadas o no. La sección de montón se
utiliza
para asignar memoria dinámicamente, conforme la necesita el programa: cuando
se solicita memoria al sistema para una estructura de datos o se crea un
objeto. El espacio libre permite, como acabamos de indicar, que el montón
pueda crecer, según lo necesite el programa. Por último, la sección de pila
sirve para mantener el flujo de control de un programa estructurado:
almacena las direcciones de memoria desde las que se realiza una llamada a
procedimiento o función (para el retorno) y reserva espacio para almacenar
las variables locales.
<p>El espacio libre, además de para el montón, sirve también al propósito de
crecimiento de la pila, aunque, en este caso, la pila empezará en la dirección
de mayor valor (podemos considerar que fuera la última dirección de memoria
disponible) y el crecimiento será "hacia abajo": se hará restando. Según la
implementación puede haber otras secciones, que el montón crezca hacia abajo
(y la pila hacia arriba), enlaces a las bibliotecas de carga dinámica... pero
éste es el esquema básico.
<p>Dentro de la memoria principal, el S.O. se encarga de hacer
creer a cada programa que es el único que se está ejecutando.
Esto lo realiza mediante la denominada
<a href=https://es.wikipedia.org/wiki/Segmentaci%C3%B3n_de_memoria>segmentación de memoria</a>:
asignar a cada programa un espacio de memoria propio. La segmentación se
inventó, originalmente, para aislar diferentes programas y los datos que
estaban usando. La segmentación permite que varios programas compartan la
memoria sin que cualquiera de ellos pueda utilizar la memoria reservada a
otro. El direccionamiento se realiza mediante una técnica denominada
"desplazamiento". Cada dirección se representa mediante dos valores:
número de segmento (s) y desplazamiento dentro del segmento (d); el
procesador mantiene un registro de la dirección "s" en la que empieza cada
segmento, con lo que el programa solo tiene que trabajar con "d".
<div class=image id=img_01_02 style="width:80%; margin-left:10%">
	<img src=imagenes/01_02_segmentacion.png
	     alt="Segmentación de la memoria">
	<p class=caption>División de la memoria en segmentos para ejecutar
	varios programas simultáneamente
</div>
<aside>
Aunque pueda parecer confuso porque hemos utilizado los
términos <em>segmento</em> y <em>segmentación</em> con
significados diferentes, en realidad, es el mismo principio.
Pero tal y como lo hemos explicado, en el primer caso hace referencia a
una organización lógica, de un programa, mientras que en el segundo lo hace
a una distribución física, de la memoria del ordenador.
<br>
En la actualidad, no obstante, para la división de la memoria
se utiliza preferentemente una técnica diferente denominada
<a href=https://es.wikipedia.org/wiki/Paginaci%C3%B3n_de_memoria>paginación de memoria</a>.
</aside>

			</section>
			<section id=Proceso>
				<header>
					<h1 id=proceso>¿Qué es un proceso?</h1>
				</header>
				<p>
Un proceso es, en esencia, un programa en ejecución. Cada proceso tiene
asociado un espacio de direcciones, una lista de ubicaciones de memoria
que va desde algún mínimo -generalmente cero- hasta cierto valor máximo, donde
el proceso puede leer y escribir información.
<p class=cita style="width:80%;margin-left:10%">Un
proceso es un recipiente que guarda toda la información necesaria para
ejecutar un programa.
<br><span class=autor>Tanenbaum</span>
<p>Para mantener los distintos programas que se ejecutan en el sistema, el S.O.
mantiene una tabla de procesos, un vector con una entrada por proceso
denominada <b>PCB</b> (<b><i>Process Control Block</i></b> – bloque de control
del proceso),
que contiene la información relevante acerca del proceso: contador de
programa, apuntador de pila… y datos propios de identificación para el S.O.
como un identificador numérico, el identificador del proceso padre, ficheros abiertos,
datos estadísticos, etc.
<p>Un proceso puede crearse en el arranque del sistema o porque, desde otro
proceso, se solicita al S.O. que lo cree. Vamos a considerar solo la segunda
opción. Para crear el proceso (hijo), el que ya está en ejecución (proceso
padre) realiza una llamada al sistema (invoca una función del S.O.) para
crearlo: <span class=llamadaSO>fork</span>. Dicha llamada crea un clon exacto
del proceso que la realiza: crea un copia de su PCB, modificando los datos
pertinentes. Ahora los dos procesos, padre e hijo, tienen los mismos datos:
 memoria, ficheros, etc. Normalmente, la creación de un proceso hijo se
realiza para ejecutar un programa diferente (ejecutando a continuación una
llamada a
<span class=llamadaSO>execve</span>) y que éste modifique esos datos, aunque
puede redireccionar la entrada y la salida. En <i>Windows</i>, se utiliza
una llamada a la función <span class=llamadaSO>CreateProcess</span></b>.
<p>Una vez que el proceso es creado, padre e hijo tienen espacios de memoria
(segmentos) diferentes de manera que, si alguno modifica algo, dicha
modificación no es visible para el otro. En algunas implementaciones pueden
compartir, por ejemplo, la sección de texto, dado que no debe modificarse.
			</section>

			<section id=Servicio>
				<header>
					<h1 id=servicio>Qué es un servicio</h1>
				</header>
<p>Como decíamos, un proceso puede crearse en el arranque del sistema
operativo. Generalmente, se crean varios procesos: algunos de ellos se
denominan de <em>segundo plano</em>, es decir, que no están asociados a un
usuario específico (no interactúan con él/ella) sino con una función
específica. Estos procesos en segundo plano, en general, se conocen como
demonios (<i>daemons</i>), existiendo docenas de los mismos en los sistemas
operativos modernos.
<p>Los sistemas modernos, normalmente, utilizan la arquitectura
cliente-servidor, un modelo de diseño de software que divide la gestión
de los recursos (programa servidor) de la utilización de los mismos
(programa cliente). Aunque el servidor puede ser un programa cualquiera,
lo normal es que éste no interactúe con el usuario, por lo que lo más común
es que se ejecute como demonio; el nombre del programa suele añadir la letra
"<b>d</b>" al final.
<div class=image id=img_01_03 style="width:80%; margin-left:10%">
	<img src=imagenes/01_03_servicio.png style="width:80%"
	     alt="Paradigma cliente-servidor">
	<p class=caption>Paradigma cliente-servidor en dos niveles
</div>
<p>En el paradigma cliente-servidor, el cliente es la parte que, normalmente,
inicia la comunicación y el servidor recibe la petición o solicitud del
cliente, la procesa y devuelve el resultado (respuesta). La arquitectura
cliente-servidor genérica se denomina de dos niveles: el cliente es el nivel
1 y el servidor el nivel 2. A su vez, el servidor puede comunicarse con
otro servidor, adoptando la figura de cliente. Este encadenamiento de
clientes y servidores se denomina arquitectura de n-niveles, siendo la más
frecuente la de 3 niveles.

			</section>

			<section id=Estados>
				<header>
					<h1 id=estados>Estados de un proceso</h1>
				</header>
<p>En un mundo ideal, nuestro sistema dispondría de un número de
procesadores superior siempre al de programas que se ejecutan, por lo que
cada programa podría ejecutarse en un procesador diferente. Pero, de forma
análoga a cómo la memoria es segmentada para que varios ejecutables puedan
trabajar en la misma, nuestro sistema dispone de un número de procesadores
inferior al de programas, tal vez solo uno, y debemos organizar un modelo
para que todos esos programas puedan "compartir" el/los procesador/es.
<p>A la mayoría de la gente le cuesta hacer varias cosas a la vez. Por eso,
en el diseño de sistemas, se utiliza un modelo conceptual en el que todos
esos programas se asocian a procesos secuenciales. El proceso es así una
instancia de un programa que contiene los valores actuales de contador de
programa, memoria, etc.: su PCB. Conceptualmente, cada proceso tiene una CPU
virtual en la que se ejecuta. La idea reside en que, aunque solo haya un
contador de programa (real) por CPU, cada proceso tiene un contador de
programa lógico de manera que, cuando el proceso debe ejecutarse, el contador
de programa real toma el valor del contador de programa lógico de ese proceso
–y sucede lo mismo con el resto de valores del PCB necesarios para la
ejecución-. Este método de conmutación rápida de un proceso a otro se denomina
<a target=_blank href=https://es.wikipedia.org/wiki/Multiprogramaci%C3%B3n>multiprogramación</a>.
<p>Así, dado que nuestro S.O. trabaja con procesos, puede organizarlos en tres estados:
<dl>
	<dt>En ejecución
	<dd>Está utilizando la CPU (o una de ellas) en ese instante
	<dt>Listo
	<dd>Podría estar usando la CPU (o una de ellas) pero no puede
		porque está en uso por otro proceso.
	<dt>Bloqueado:
	<dd>No puede ejecutarse porque está a la espera de que ocurra
		un acontecimiento concreto (habitualmente, un evento de E/S)
</dl>
<div class=image id=img_01_04 style="width:80%; margin-left:10%">
	<img src=imagenes/01_04_estados_proceso.png style="width:60%"
	     alt="Estados de un proceso">
	<p class=caption>Estado de un proceso en el S.O.
	<br>Fuente: Sistemas operativos. Diseño e implementación.
	Andrew S. Tanenbaum. 1987
</div>
<p>En la figura pueden verse las posibles transiciones entre estos tres estados.
<p>Con este modelo es mucho más simple entender cómo funciona el S.O.: algunos
procesos ejecutan programas interactivos, otros forman parte del sistema y
responden peticiones de otros procesos… En general, los procesos "hijo" (en
el momento de su creación) obtienen el estado "listo" y, posteriormente, un
proceso especial denominado
<a target=_blank href=https://es.wikipedia.org/wiki/Planificador>planificador</a>
decide que debe pasar al estado "en ejecución", bien porque un proceso que
se encontraba en dicho estado ha pasado al estado "bloqueado", bien porque
llevaba mucho tiempo utilizando la CPU y dicho planificador ha decidido que
debía pasar al estado "listo".

			</section>

<p>Podemos dividir los algoritmos de planificación en dos categorías: no
apropiativos (<i>nonpreemptive</i>) y apropiativos. Los primeros permiten que
los procesos se ejecuten hasta que se bloquean o hasta que liberan la CPU de
forma voluntaria, no existiendo un algoritmo de planificación propiamente
dicho. En el caso de los segundos, si no se produce una de las acciones antes
comentadas, el planificador toma el control tras un período de tiempo
determinado y selecciona otro proceso (de aquellos en estado "listo").
<p>Se han propuesto múltiples métodos de planificación aunque no vamos a
tratarlos aquí. Para más información, se puede visitar la página de Wikipedia
(en inglés) sobre
<a target=_blank href=https://en.wikipedia.org/wiki/Scheduling_(computing)>
planificación</a>.


			<section id=Hilos>
				<header>
					<h1 id=hilos>Hilos</h1>
				</header>
<p>Tradicionalmente, cada proceso hace una única cosa. A veces, sin embargo,
la misma aplicación debe realizar varias actividades a la vez, algunas de las
cuales pueden bloquearse en un momento dado. En esas ocasiones puede
interesarnos tener varios flujos de control diferentes, todos en el mismo
programa. Pero… ese era el propósito de tener procesos, ¿para qué podríamos
querer tener (sub)procesos dentro de un proceso?
<p>En los primeros sistemas, que tenían un procesamiento por lotes, el
algoritmo de planificación era muy sencillo: se ejecutaba el siguiente
trabajo a realizar. En los sistemas multiprogramados, sin embargo, esto
se vuelve más complejo por la cantidad de programas y/o usuarios que pueden
estar haciendo (o esperando hacer) uso de la CPU.
<p>Además, la conmutación es una tarea con un coste elevado. Primero, debe
haber un cambio de contexto del modo del usuario al
<a target=_blank href=https://es.wikipedia.org/wiki/N%C3%BAcleo_(inform%C3%A1tica)>modo núcleo</a>. El núcleo
debe ahora guardar el estado (PCB) del proceso actual en la tabla de procesos:
esto incluye el contador de programa, otros registros de la CPU y, en la
mayoría de sistemas, el mapa de memoria del proceso (las direcciones de
memoria que ocupa). A continuación, se ejecuta el algoritmo de planificación
para elegir cuál es el nuevo proceso que debe ejecutarse. Y realizar el
proceso inverso: copiar el mapa de memoria, los registros y el contador de
programa. Y sin olvidar que toda la
<a target=_blank href=https://es.wikipedia.org/wiki/Cach%C3%A9_(inform%C3%A1tica)>memoria caché</a>
ha quedado invalidada,
tanto al entrar en modo núcleo como para el nuevo proceso, por lo que debe
cargarse de la memoria principal en dos ocasiones.
<p>Nuestro interés reside en que estos miniprocesos o <b>hilos</b>
(<em>threads</em>)
tienen la habilidad de utilizar un espacio de direcciones compartido, con
todos los datos que contengan. Otra característica interesante es que el
coste de crearlos (y destruirlos) es muy inferior al de crear (y destruir)
procesos: entre 10 y 100 veces. En tercer lugar, un bloqueo en E/S no afecta
a todo el proceso ya que otro hilo puede seguir ejecutándose. Y por último,
en máquinas con múltiples CPU, se puede llegar a lograr un paralelismo real.
<aside>
Los hilos comparten todo el espacio de direcciones del proceso al que
pertenecen a excepción de la pila: cada hilo tiene su propia pila. Esto
permite que cada uno tenga su propio flujo de control del programa.
</aside>
<p>Dado que todos los hilos de un proceso comparten su mismo espacio de
direcciones, cualquiera de ellos puede acceder a los datos o incluso la pila
de otro hilo. No existe protección entre hilos porque no es posible, pero
tampoco es necesaria: se supone que se crean para cooperar. El PCB de todos
los hilos será el mismo (dado que corresponden al mismo proceso) pero cada
uno de ellos debe tener su propio registro de datos, denominado <b>TCB</b>
(<b><i>Thread Control Block</i></b> – bloque de control del hilo) que
contendrá su propio contador de programa, registros del procesador, pila
y estado (de ejecución).
<aside>Al hablar sobre los procesadores actuales, se escuchan mucho los términos
<em>cores</em> y <em>threads</em> debido a una tecnología denominada
<b><i>hyper-threading</i></b>. No deben confundirse los conceptos que
estamos estudiando con esta tecnología. HT se basa en la duplicación de
algunos recursos del procesador –que no incluyen las unidades de cómputo-
para que, si una de dichas unidades se debe detener, otro hilo de ejecución
pueda utilizar unidades que están desocupadas. Esto proporciona, de cara al
sistema operativo, la perspectiva de que tiene dos procesadores lógicos.
Por ello, para nosotros, es como si el sistema tuviera dos procesadores,
al margen de que sean reales (<i>cores</i>) o lógicos (<i>threads</i>).
</aside>

			</section>

			<section>
				<header>
					<h1 id=tiposp>Tipos de programación</h1>
				</header>
<p>Ahora que sabemos cómo gestiona un sistema operativo el que puedan
ejecutarse diferentes cosas en una misma máquina, vamos a explicar la
diferencia entre programación concurrente, paralela y distribuida.
<p>Programación concurrente es aquella en la que se ejecutan múltiples
tareas, sea a través de un conjunto de procesos o de hilos, creados por
un único programa. Es lo que antes hemos denominado multiprogramación.
<p>La programación paralela es una técnica en la que varias instrucciones
pueden ejecutarse de forma simultánea. Su principio básico es que los
problemas pueden resolverse dividiéndolos en partes más pequeñas que pueden
ejecutarse de forma concurrente. ¿La programación paralela es entonces
programación concurrente? En realidad, la programación concurrente es un
modo de programación paralela que enfatiza el hecho de la interacción entre
tareas, tareas que trabajan sobre un mismo recurso. Podríamos decir que
programación paralela se produce cuando podemos realizar tareas que son
independientes unas de las otras; mientras que concurrente es aquella en la
que existe alguna dependencia entre las mismas, que las tareas deben acceder
a recursos que comparten, haciéndolo de forma ordenada. Los sistemas actuales,
en la mayoría de los casos, disponen de varios procesadores, por lo que ha
aumentado el interés en la programación paralela.
<p>La programación distribuida es una forma de programación paralela (y/o
concurrente) en la que se utilizan diferentes máquinas, conectadas por
algún tipo de red de comunicaciones. Es decir, esas partes más pequeñas que
pueden ejecutarse simultáneamente se reparten entre máquinas independientes,
pero comunicadas.
			</section>
			<section id=JVM>
				<header>
					<h1 id=jvm>La máquina virtual de Java</h1>
				</header>
<aside>
Toda la información aquí mostrada está basada en la 
<a href=https://docs.oracle.com/javase/specs/jvms/se14/html/index.html>especificación de la JVM</a>, más concretamente, en los puntos 1.1, 1.2 y 2.5. La
introducción a los parámetros de la aplicación <em>java</em>, en su
<a href=https://docs.oracle.com/en/java/javase/14/docs/specs/man/java.html>
página de manual</a>.
</aside>
<p>En un principio, la <i>Java platform</i> se desarrolló con la idea de
proporcionar un entorno seguro de despliegue de componentes software, con
soporte para múltiples plataformas. El éxito de la <i>World Wide Web</i> hizo
que creciera el interés en estas características hasta nuestros días,
definiendo Java como un <em><b>WORA</b></em> (Write Once Run Everywhere), que
significa que el programador puede desarrollar su software en Java y éste se
podrá ejecutar en cualquier sistema con soporte al <em>entorno de ejecución
de Java</em>.
<p>Un componente fundamental de este entorno, obviamente, es la
<em><b>JVM</b></em> (Máquina Virtual de Java). La JVM es un ordenador
abstracto que, como una máquina real, tiene un conjunto de instrucciones y
gestiona varias áreas de memoria en tiempo de ejecución. La JVM, en realidad,
no sabe nada acerca del lenguaje de programación Java, aparte de un formato
binario particular: el formato de <em>fichero <b>class</b></em>. Este tipo de
fichero contiene instrucciones de la JVM (código denominado
<em><b>bytecode</b></em>), una tabla de símbolos e información auxiliar. Un
fichero <em>.class</em> es el resultado de compilar, con el compilador de
Java, vuestro fichero <em>.java</em>. 
Cualquier lenguaje de programación, no necesariamente Java, se podría utilizar
para generar código que se ejecute en la JVM.

<h2>Organización de la memoria</h2>
<p>Decimos que la JVM es una máquina abstracta; eso significa que nuestros
programas tendrán que estar organizados en la memoria como en una máquina
real o de modo similar. De hecho, el modelo no difiere mucho del de la
segmentación que veíamos al principio.
<p>En nuestro modelo empezábamos por la sección de texto. En la JVM esto es
denominado <em><b>Method Area</b></em>. Contiene el código de las clases que,
dependiendo de la implementación, puede ser de tamaño fijo o variable; es
decir, que, en caso de ser variable, puede crecer o disminuir según se
requiera. Tanto ésta como el resto de áreas que vamos a describir, en caso de
requerir más memoria de la disponible, generará un error
<a class=clase target=_blank
   href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/lang/OutOfMemoryError.html>OutOfMemoryError</a> de la JVM.
<br>Nota: En el <a href=03_progsec.html>capítulo 3</a> se explican las
excepciones.
<p>A continuación, veíamos la sección de datos. En el caso de la JVM ésta se
puede identificar con la <em><b>Run-Time Constant Pool</b></em>. Pero este
área es por clase o interface y contiene mucha más información que la típica,
para esta sección, en un programa normal. Además, la memoria utilizada para la
sección de la JVM es tomada de la <em><b>Method Area</b></em>, creándose
cuando la JVM construye la clase o el interfaz.
<p>Sea ahora el área equivalente al montón: <em><b>Heap</b></em>. Esta zona
de memoria, que almacenará los objetos creados durante la ejecución del
programa, puede, como antes la <em><b>Method Area</b></em>, ser de tamaño fijo
o variable. Lo interesante de la misma es que, como los objetos de Java no son
liberados de forma explícita, debe existir un sistema gestor de almacenamiento
automático, denominado <b>recolector de basura</b> (<i>garbage collector</i>).
La JVM no especifica cómo debe ser dicho gestor y deja al implementador elegir
la técnica a utilizar.
<p>Y finalizamos con la pila: <em><b>Java Virtual Machine Stack</b></em>. A
diferencia del resto de áreas, que son comunes para todo el programa, la pila
es exclusiva, y privada, de cada hilo; es decir, que habrá tantas pilas como
hilos, creándose a la vez que éstos. Almacena las variables locales y la
información necesaria para la invocación de métodos y su retorno. Como antes,
pueden ser de tamaño fijo o variable, según la implementación. Además de el
<span class=clase>OutOfMemoryError</span>, puede generar uno
<a class=clase target=_blank
   href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/lang/StackOverflowError.html>StackOverflowError</a>
si el programa requiere una pila mayor de la permitida.
<p>Aunque no es un área de memoria propiamente dicha, la especificación
contiene también un <em><b>pc Register</b></em>, contador de programa, que es
propio de cada hilo y contiene la dirección de la instrucción de la JVM que
está en ejecución.

<h3>Parámetros de la JVM</h3>
<p>La JVM se activa utilizando el comando <em>java</em> (o <em>javaw</em>),
seguido del programa a ejecutar, el que contiene la clase con el método
<span class=metodo>main</span>(). El <a href=/anexos/01_anexo>Anexo I</a>
explica cómo se puede ejecutar un programa en Java.
<p>Entre el comando y el programa a ejecutar podemos especificar opciones que
determinarán cómo se ejecuta. De esas opciones, las que nos interesan son las
que van a determinar la cantidad de memoria que la JVM utilizará. Estas
opciones se encuentran entre las denominadas
<a href=https://docs.oracle.com/en/java/javase/14/docs/specs/man/java.html#extra-options-for-java>Opciones extra</a>
y, de las mismas, las que hacen referencia a los tamaños de pila y montón.
<p>Las opciones que decimos empiezan por <em>-X</em> y son específicas de la
implementación, por lo que no se garantiza que una JVM diferente a la de
Oracle las utilice. Existen también opciones avanzadas, que comienzan por
<em>-XX</em>, que contemplan estos controles y más.
<p>Contamos con tres opciones para la gestión del montón (-Xmn, -Xms y -Xmx) y
una para la de la pila (-Xss). Todas ellas van seguidas del tamaño en octetos,
aunque podemos especificarlas en <i>kilobytes</i> (con el sufijo <em>k</em> o
<em>K</em>), <i>megabytes</i> (<em>m</em> o <em>M</em>) o <i>gigabytes</i>
(<em>g</em> o <em>G</em>). Por ejemplo, un tamaño de 4MB puede indicarse como:
<br><span class=code>-Xmx4m</span>
<br><span class=code>-Xmx4096k</span>
<br><span class=code>-Xmx4194304</span>
<p>La opción <em>-Xmx</em> determina el tamaño máximo, que debe ser múltiplo
de 1024 y mayor que 2MB; el tamaño por defecto se elige en tiempo de
ejecución, según la configuración del sistema. <em>-Xms</em> determina el
tamaño mínimo e inicial, que debe ser múltiplo de 1024 y mayor que 1MB. Pero,
¿por qué querríamos cambiar estos valores? La JVM se ajusta bien a la mayoría
de programas pero si necesitamos tener muchos objetos o algunos muy grandes,
puede interesarnos adaptarla a nuestras necesidades.
<p>Por último, <em>-Xmn</em> indica el tamaño inicial y máximo del montón
para la generación 0 del recolector de basura. Como puedes imaginar, utiliza
un recolector de basura generacional; vamos a ver cuál es la idea básica de
forma simple: dispone secciones para almacenar los objetos; por defecto,
se crean en esta (generación 0) y, cuando el espacio se ha llenado, los
objetos aún en uso se trasladan a la siguiente sección (generación 1) y el
resto se eliminan. En todos las secciones se utiliza este algoritmo. La
recomendación es que el tamaño de la generación 0 esté entre el 25% y el 50%
del tamaño total del montón.
<p>El tamaño de la pila es establecido con <em>-Xss</em>. El tamaño es el que
se asigna a cada hilo. El valor por defecto es 1MB en los sistemas tipo UNIX,
pero en Windows depende de la memoria virtual.

<h2>Ejercicios</h2>
<p>Crea un programa Java que sea capaz de contener una estructura con mil
millones de elementos. Los elementos serán números reales, en doble
precisión, a los que asignarás un valor aleatorio, de uno en uno.
<ol>
	<li>Usa un vector de <em>double</em>. ¿Has tenido algún problema?
	Si lo has tenido, ¿has podido solucionarlo? ¿Cómo?
<br>Nota: si el ordenador en que realizas la prueba tiene menos de 16GB
es posible que tarde mucho tiempo: imprime un mensaje justo antes de que
comience a asignar valores a los elementos del vector y, cuando lo veas
impreso en la consola, puedes detener el programa.
	<li>Utiliza ahora una colección como, por ejemplo, un
		<a class=clase target=_blank
		   href=https://docs.oracle.com/en/java/javase/14/docs/api/java.base/java/util/ArrayList.html#%3Cinit%3E()>ArrayList</a>.
	   ¿Ha habido algún problema? Si así hubiera sido, ¿a qué crees que
	   es debido?
<br>Nota: para supervisar la tarea, imprime un mensaje, por ejemplo, cada vez
que hayas asignado valor y añadido al <span class=clase>ArrayList</span>
1000 elementos.

</ol>
			</section>
			<footer>
<nav class=pie>
	<a class=previo></a>
	<a class=inicio href=index.html>Índice</a>
	<a class=siguiente href=02_multip.html>Programación multiproceso</a>
</nav>
		<p>Programación de servicios y procesos</p>
			</footer>
		</article>
	</body>
</html>
